name: Claude Code with LiteLLM Proxy - Advanced Configuration
on:
  issues:
    types: [opened, edited]
  issue_comment:
    types: [created, edited]
  pull_request:
    types: [opened, edited, synchronize]
  pull_request_review_comment:
    types: [created, edited]

jobs:
  claude:
    runs-on: ubuntu-latest
    steps:
      - name: Claude Code with LiteLLM Proxy - Multi-Provider Setup
        uses: ./
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          # LiteLLM Proxy Configuration
          anthropic_base_url: "https://api.my-company.com/litellm" # Your LiteLLM proxy URL
          anthropic_api_key: ${{ secrets.LITELLM_API_KEY }} # API key for LiteLLM proxy

          # Model Configuration
          model: "claude-3-5-sonnet-20241022" # Primary model
          fallback_model: "openai/gpt-4" # Fallback model

          # Additional Configuration
          max_turns: "10"
          system_prompt: |
            You are a helpful coding assistant working through a LiteLLM proxy.
            You have access to multiple AI providers and should choose the best model for each task.

          # Claude-specific environment variables for the proxy
          claude_env: |
            LITELLM_LOG=INFO
            LITELLM_MASTER_KEY=${{ secrets.LITELLM_MASTER_KEY }}
